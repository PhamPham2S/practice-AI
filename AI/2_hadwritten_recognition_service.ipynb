{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd6bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import os\n",
    "import unicodedata\n",
    "from io import BytesIO\n",
    "\n",
    "# ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoTokenizer\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c036b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97612b6b1c94da8ac1feb30c8ffde14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/364 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ebb6e279f84c7582694bd12f151bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/475 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fae6976e284b71ba8fb4dbe7baa285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/104k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2580ff785a548158f8d7ffe710f50ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/358k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1744f0e303ad47f182528ea64354add4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/my_env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e32c974ac44ec4aa5716a4a4389f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe99983523d4f83956ac54dc91c0482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/427M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VisionEncoderDecoderModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§€ë°©í† ëª©ì£¼ì‚¬\n"
     ]
    }
   ],
   "source": [
    "# TrOCR ëª¨ë¸ê³¼ ê´€ë ¨ëœ ì „ì²˜ë¦¬ê¸°, ëª¨ë¸, í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜´\n",
    "processor = TrOCRProcessor.from_pretrained(\"ddobokki/ko-trocr\")  # TrOCR ì „ì²˜ë¦¬ê¸°\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"ddobokki/ko-trocr\")  # TrOCR ë¹„ì „-í…ìŠ¤íŠ¸ ëª¨ë¸\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ddobokki/ko-trocr\")  # TrOCR ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì €\n",
    "\n",
    "# URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "url = \"https://raw.githubusercontent.com/ddobokki/ocr_img_example/master/g.jpg\"\n",
    "response = requests.get(url)  # URLë¡œë¶€í„° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "img = Image.open(BytesIO(response.content))  # ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ì—¬ ì—´ê¸°\n",
    "\n",
    "# ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ëª¨ë¸ ì…ë ¥ê°’ìœ¼ë¡œ ì „ì²˜ë¦¬\n",
    "pixel_values = processor(img, return_tensors=\"pt\").pixel_values  # ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì— ë§ëŠ” í…ì„œë¡œ ë³€í™˜\n",
    "\n",
    "# ëª¨ë¸ì„ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ ìƒì„± (OCR ìˆ˜í–‰)\n",
    "generated_ids = model.generate(pixel_values, max_length=64)  # ì´ë¯¸ì§€ë¡œë¶€í„° í…ìŠ¤íŠ¸ í† í° ìƒì„±\n",
    "generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]  # í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì •ê·œí™” (NFC í˜•ì‹)\n",
    "generated_text = unicodedata.normalize(\"NFC\", generated_text)  # ìœ ë‹ˆì½”ë“œ ì •ê·œí™”ë¡œ í…ìŠ¤íŠ¸ í†µì¼\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(generated_text)  # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c226f5a-9403-41ec-b23d-7288703eda26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] init TrOCR Inferencer\n"
     ]
    }
   ],
   "source": [
    "# TrOCRInferencer í´ë˜ìŠ¤ ì •ì˜ - ëª¨ë¸, ì „ì²˜ë¦¬ê¸°, í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì™€ ì„¤ì •\n",
    "class TrOCRInferencer:\n",
    "    def __init__(self):\n",
    "        # ì´ˆê¸°í™” ì‹œ, ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸°, í† í¬ë‚˜ì´ì €ë¥¼ ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ì—ì„œ ë¶ˆëŸ¬ì˜´\n",
    "        print(\"[info] init TrOCR Inferencer\")\n",
    "        self.processor = TrOCRProcessor.from_pretrained(\"ddobokki/ko-trocr\")\n",
    "        self.model = VisionEncoderDecoderModel.from_pretrained(\"ddobokki/ko-trocr\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"ddobokki/ko-trocr\")\n",
    "        \n",
    "    # ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ë©”ì„œë“œ\n",
    "    def inference(self, image):\n",
    "        # ì´ë¯¸ì§€ë¥¼ í…ì„œ í˜•ì‹ìœ¼ë¡œ ì „ì²˜ë¦¬\n",
    "        pixel_values = self.processor(images=image, return_tensors='pt').pixel_values\n",
    "        # ëª¨ë¸ì„ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ í† í° ìƒì„±\n",
    "        generated_ids = self.model.generate(pixel_values, max_length=64)\n",
    "        # í† í°ì„ ì‹¤ì œ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "        generated_text = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        # ìœ ë‹ˆì½”ë“œ ì •ê·œí™”ë¡œ í…ìŠ¤íŠ¸ ì •ë¦¬\n",
    "        generated_text = unicodedata.normalize(\"NFC\", generated_text)\n",
    "        \n",
    "        return generated_text\n",
    "\n",
    "# TrOCRInferencer ê°ì²´ ìƒì„±\n",
    "inferencer = TrOCRInferencer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f66301dc-aee6-4ebb-8758-7261308d4bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_text(image):\n",
    "    # dict í˜•íƒœì¼ ê²½ìš° composite ì´ë¯¸ì§€ ì¶”ì¶œ\n",
    "    if isinstance(image, dict):\n",
    "        image = image.get('composite', None)  # 'composite' í‚¤ì— ì ‘ê·¼\n",
    "        if image is None:\n",
    "            return \"No valid image data found\"\n",
    "    \n",
    "    # ì´ë¯¸ì§€ê°€ NumPy ë°°ì—´ì¼ ê²½ìš° ì²˜ë¦¬\n",
    "    image = Image.fromarray(image).convert('RGB')\n",
    "    \n",
    "    try:\n",
    "        # ì¶”ë¡ ì„ í†µí•´ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        text = inferencer.inference(image)\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef383ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://a4bab1cafe69ff7113.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    }
   ],
   "source": [
    "brush = gr.Brush(default_size = 3)\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì •ì˜\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Handwritten Image OCR\")  # ì•± ì œëª©\n",
    "    # ì²« ë²ˆì§¸ íƒ­: ì´ë¯¸ì§€ ì—…ë¡œë“œ ë°©ì‹\n",
    "    with gr.Tab(\"Image upload\"):\n",
    "        image = gr.Image(label=\"Handritten image file\")  # ì´ë¯¸ì§€ ì—…ë¡œë“œ ì»´í¬ë„ŒíŠ¸\n",
    "        output = gr.Textbox(label=\"Output Box\")  # ê²°ê³¼ í…ìŠ¤íŠ¸ ë°•ìŠ¤\n",
    "        convert_btn = gr.Button(\"Convert\")  # ë³€í™˜ ë²„íŠ¼\n",
    "        # ë²„íŠ¼ í´ë¦­ ì‹œ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œ\n",
    "        convert_btn.click(\n",
    "            fn=image_to_text, inputs=image, outputs=output\n",
    "        )\n",
    "        # ì˜ˆì‹œ ì´ë¯¸ì§€ ê¸°ëŠ¥ (ì£¼ì„ ì²˜ë¦¬ë¨)\n",
    "        # gr.Markdown(\"## Image Examples\")\n",
    "        # gr.Examples(\n",
    "        #     examples=[\n",
    "        #         os.path.join(os.getcwd(), \"examples/Hello.png\"),\n",
    "        #         os.path.join(os.getcwd(), \"examples/Hello_cursive.png\"),\n",
    "        #         os.path.join(os.getcwd(), \"examples/Red.png\"),\n",
    "        #         os.path.join(os.getcwd(), \"examples/sentence.png\"),\n",
    "        #         os.path.join(os.getcwd(), \"examples/i_love_you.png\"),\n",
    "        #         os.path.join(os.getcwd(), \"examples/merrychristmas.png\"),\n",
    "        #         os.path.join(os.getcwd(), \"examples/Rock.png\"),\n",
    "        #         os.path.join(os.getcwd(), \"examples/Bob.png\"),\n",
    "        #     ],\n",
    "        #     inputs=image,\n",
    "        #     outputs=output,\n",
    "        #     fn=image_to_text\n",
    "        # )\n",
    "    \n",
    "    # ë‘ ë²ˆì§¸ íƒ­: ìŠ¤ì¼€ì¹˜ íŒ¨ë“œë¡œ ì†ê¸€ì”¨ ì‘ì„±\n",
    "    with gr.Tab(\"Drawing\"):\n",
    "        gr.Markdown(\"# Handwritten Image OCR\")  # íƒ­ ì œëª©\n",
    "        # ìŠ¤ì¼€ì¹˜íŒ¨ë“œ ì»´í¬ë„ŒíŠ¸ (ì‚¬ìš©ìê°€ ì†ê¸€ì”¨ë¥¼ ê·¸ë¦¼)\n",
    "        sketchpad = gr.Sketchpad(\n",
    "            label = \"Handwritten Sketchpad\",  # ë¼ë²¨ëª… ìˆ˜ì •\n",
    "            width=600,  # ìŠ¤ì¼€ì¹˜íŒ¨ë“œ ë„ˆë¹„\n",
    "            height=400,  # ìŠ¤ì¼€ì¹˜íŒ¨ë“œ ë†’ì´\n",
    "            brush=brush,\n",
    "            container=True,  # ë ˆì´ì•„ì›ƒ í¬ê¸° ê³ ì •\n",
    "            scale=2,  # í¬ê¸° ë¹„ìœ¨ ì„¤ì •\n",
    "        )\n",
    "        output = gr.Textbox(label=\"Output Box\")  # ê²°ê³¼ í…ìŠ¤íŠ¸ ë°•ìŠ¤\n",
    "        convert_btn = gr.Button(\"Convert\")  # ë³€í™˜ ë²„íŠ¼\n",
    "        # ë²„íŠ¼ í´ë¦­ ì‹œ ìŠ¤ì¼€ì¹˜íŒ¨ë“œì—ì„œ ì‘ì„±í•œ ê·¸ë¦¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "        convert_btn.click(\n",
    "            fn=image_to_text, inputs=sketchpad, outputs=output\n",
    "        )\n",
    "\n",
    "app.launch(inline=False, share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
