{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d3fbf39-79e5-42c8-9021-2b4894fe00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cffd4d6-5a92-4f08-9d6a-dda4a4c420fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New Jeans also contain the desire to be an icon of the age as they will be found every day and when they don’t wear, and to open a new age at the same time.']\n",
      "['NewJeans는 시간의 아이콘이되기위한 야망, 당신이 매일 도달하고 착용에 지쳤을 때 결코 찾을 수있는 제인과 같은, 그리고 새로운 시대를 열기위한 결심을 가지고 있습니다.']\n"
     ]
    }
   ],
   "source": [
    "ko_text = \"뉴진스에는 매일 찾게 되고 언제 입어도 질리지 않는 진처럼 시대의 아이콘이 되겠다는 포부와 새로운 시대를 열겠다는 각오도 동시에 담겨 있다.\"\n",
    "en_text = \"NewJeans carries both the ambition of becoming an icon of the times, like jeans that you find yourself reaching for every day and never get tired of wearing, and the determination to open a new era.\"\n",
    "\n",
    "# 모델과 토크나이저 불러오기\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "\n",
    "# 한국어를 영어로 번역\n",
    "tokenizer.src_lang = \"ko\"\n",
    "encoded_ko = tokenizer(ko_text, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(**encoded_ko, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n",
    "translated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "print(translated_text)\n",
    "\n",
    "# 영어를 한국어로 번역\n",
    "tokenizer.src_lang = \"en\"\n",
    "encoded_en = tokenizer(en_text, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.get_lang_id(\"ko\"))\n",
    "translated_text2 = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "print(translated_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce893298-d3ae-45d6-85f7-7d078a0779f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b189f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/my_env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# CPU 디바이스로 설정 (DirectML 대신 CPU 사용)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 번역 모델 초기화 및 CPU로 이동\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\").to(device)\n",
    "\n",
    "# 토크나이저 초기화\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "\n",
    "# 언어와 언어 코드 목록\n",
    "languages = {\n",
    "    \"Korean\": \"ko\",\n",
    "    \"English\": \"en\",\n",
    "    \"French\": \"fr\",\n",
    "    \"Spanish\": \"es\",\n",
    "    \"German\": \"de\",\n",
    "    \"Japanese\": \"ja\",\n",
    "    \"Chinese (Simplified)\": \"zh\",\n",
    "    \"Russian\": \"ru\",\n",
    "    # 필요 시 더 추가\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0048712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://bd7268f497ebe23d36.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 번역 함수\n",
    "def translate(text, source_lang, target_lang):\n",
    "    tokenizer.src_lang = languages[source_lang]\n",
    "    encoded_text = tokenizer(text, return_tensors=\"pt\").to(device)  # CPU로 이동\n",
    "    generated_tokens = model.generate(**encoded_text, forced_bos_token_id=tokenizer.get_lang_id(languages[target_lang]))\n",
    "    translated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "    return translated_text\n",
    "\n",
    "# Gradio 앱 빌드\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Multilingual Translation Service\")\n",
    "\n",
    "    with gr.Row():\n",
    "        source_lang = gr.Dropdown(label=\"Source Language\", choices=list(languages.keys()), value=\"Korean\")\n",
    "        target_lang = gr.Dropdown(label=\"Target Language\", choices=list(languages.keys()), value=\"English\")\n",
    "\n",
    "    input_text = gr.Textbox(label=\"Input Text\")\n",
    "    output_text = gr.Textbox(label=\"Translated Text\")\n",
    "    translate_btn = gr.Button(\"Translate\")\n",
    "\n",
    "    # 번역 버튼 클릭 시 동작 설정\n",
    "    translate_btn.click(fn=translate, inputs=[input_text, source_lang, target_lang], outputs=output_text)\n",
    "\n",
    "# Gradio 앱 실행\n",
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ba27a",
   "metadata": {},
   "source": [
    "# 읽기 기능 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d480843a-78f2-4a5b-855f-a7dab6151a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0625c54-b49c-40e8-967e-84c0017deaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/my_env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# CPU 디바이스로 설정 (DirectML 대신 CPU 사용)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 번역 모델과 토크나이저 초기화 및 CPU로 이동\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\").to(device)\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "\n",
    "# 언어 목록 및 언어 코드\n",
    "languages = {\n",
    "    \"Korean\": \"ko\",\n",
    "    \"English\": \"en\",\n",
    "    \"French\": \"fr\",\n",
    "    \"Spanish\": \"es\",\n",
    "    \"German\": \"de\",\n",
    "    \"Japanese\": \"ja\",\n",
    "    \"Chinese (Simplified)\": \"zh\",\n",
    "    \"Russian\": \"ru\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0c6a4ff-b3da-4ae7-b014-f0f24f62a219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e93b48ebd74432b6880809ad37f764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbbbdeadb5745ddb963315f87f6aad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/232 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b713d9e0e05c45799389d889820d93a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm_char.model:   0%|          | 0.00/238k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde5521d7d0b468994a9a71eb619ad3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6c1059e02c44bf9e4f9ab77515ae3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4e5c985d9e44c0bd2b5a2284ad02b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491f8dc189e6498992930490c8c3b34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/585M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4eada8f2c341e1841c9e897f53ff5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351cf00003c140fba8980ebcf1d8d598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/50.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e0e8c1eab0449ea3ec4a8118bcb4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/21.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c11844fadaf42279a03afde4bda9828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/7931 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Microsoft SpeechT5 TTS 모델 로드\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "speech_model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\").to(device)  # CPU로 이동\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\").to(device)  # CPU로 이동\n",
    "\n",
    "# 음성 특성을 위한 스피커 임베딩 데이터셋 로드\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "\n",
    "# 번역 및 TTS 함수\n",
    "def translate_and_tts(text, source_lang, target_lang):\n",
    "    # 언어 설정 후 번역\n",
    "    tokenizer.src_lang = languages[source_lang]\n",
    "    encoded_text = tokenizer(text, return_tensors=\"pt\").to(device)  # 입력 데이터를 CPU로 이동\n",
    "    generated_tokens = model.generate(**encoded_text, forced_bos_token_id=tokenizer.get_lang_id(languages[target_lang]))\n",
    "    translated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # 대상 언어가 영어일 경우 TTS 수행\n",
    "    tts_output_file = None\n",
    "    if target_lang == \"English\":\n",
    "        tts_output_file = convert_text_to_speech(translated_text)\n",
    "    \n",
    "    return translated_text, tts_output_file\n",
    "\n",
    "# 텍스트를 음성으로 변환하는 함수\n",
    "def convert_text_to_speech(text):\n",
    "    inputs = processor(text=text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # 스피커 임베딩 선택\n",
    "    speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0).to(device)\n",
    "    \n",
    "    # TTS 모델과 vocoder를 사용하여 음성 생성\n",
    "    speech = speech_model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
    "    \n",
    "    # 생성된 음성을 파일로 저장\n",
    "    temp_audio_file = \"output_speech.wav\"\n",
    "    sf.write(temp_audio_file, speech.numpy(), samplerate=16000)\n",
    "    \n",
    "    return temp_audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "615a4be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://5e80d6cfc33cab0106.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Multilingual Translation Service with Microsoft SpeechT5 TTS\")\n",
    "\n",
    "    with gr.Row():\n",
    "        source_lang = gr.Dropdown(label=\"Source Language\", choices=list(languages.keys()), value=\"Korean\")\n",
    "        target_lang = gr.Dropdown(label=\"Target Language\", choices=list(languages.keys()), value=\"English\")\n",
    "\n",
    "    input_text = gr.Textbox(label=\"Input Text\")\n",
    "    output_text = gr.Textbox(label=\"Translated Text\")\n",
    "    tts_audio = gr.Audio(label=\"Text-to-Speech Output\")  # Audio player for speech output\n",
    "    translate_btn = gr.Button(\"Translate and Speak\")\n",
    "\n",
    "    # Connect the button click event to the translation and TTS function\n",
    "    translate_btn.click(fn=translate_and_tts, inputs=[input_text, source_lang, target_lang], outputs=[output_text, tts_audio])\n",
    "\n",
    "app.launch(inline=False, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
